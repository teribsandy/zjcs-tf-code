{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "\n",
    "sdata=data[cols].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "     Survived  Pclass  Sex        Age  SibSp  Parch      Fare  Embarked\n",
      "821         1       3    1  27.000000      0      0    8.6625         2\n",
      "384         0       3    1  29.699118      0      0    7.8958         2\n",
      "14          0       3    0  14.000000      0      0    7.8542         2\n",
      "182         0       3    1   9.000000      4      2   31.3875         2\n",
      "716         1       1    0  38.000000      0      0  227.5250         0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def prepare(sdata):\n",
    "    sdata['Age']=sdata['Age'].fillna(sdata['Age'].mean())\n",
    "    sdata['Embarked']=sdata['Embarked'].fillna('S')\n",
    "    print (sdata.isnull().sum())\n",
    "\n",
    "    sdata['Sex']=sdata['Sex'].map({'female':0,'male':1}).astype(int)\n",
    "    sdata['Embarked']=sdata['Embarked'].map({'C':0,'Q':1,'S':2}).astype(int) \n",
    "\n",
    "    print (sdata[:5])\n",
    "\n",
    "    features=sdata.drop(['Survived'],axis=1) #DataFrame (891,7)\n",
    "    f=features.values  #ndarray (891,7)\n",
    "\n",
    "    scale=preprocessing.MinMaxScaler() \n",
    "    norm_features=scale.fit_transform(f) #ndarray (891,7)\n",
    "\n",
    "    #scale.fit_transfrom()传入不管是features还是f，输出的都是ndarray数组\n",
    "    #因此，我们最好还是令函数的返回值统一为ndarray类型\n",
    "    labels=sdata[['Survived']] #DataFrame (891,1)\n",
    "    labels=labels.values #ndarray (891,1)\n",
    "    \n",
    "    return norm_features,labels\n",
    "\n",
    "norm_features,labels=prepare(sdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=int(len(norm_features)*0.8)\n",
    "\n",
    "x_train=norm_features[:size]\n",
    "y_train=labels[:size]\n",
    "\n",
    "x_test=norm_features[size:]\n",
    "y_test=labels[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/dayuse/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/dayuse/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "\n",
    "#隐层1\n",
    "model.add(tf.keras.layers.Dense(units=64,\n",
    "                                #input_shape=(7,)\n",
    "                                input_dim=7,\n",
    "                               activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "#隐层2\n",
    "model.add(tf.keras.layers.Dense(units=32,\n",
    "                               activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "#输出层\n",
    "model.add(tf.keras.layers.Dense(units=1,\n",
    "                               activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.003),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置回调参数\n",
    "\n",
    "tf.keras.callbacks.TensorBoard\n",
    "tf.keras.callbacks.ModelCheckpoint\n",
    "tf.keras.callbacks.LearningRateScheduler\n",
    "tf.keras.callbacks.EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本代码所在目录并无logs和ckpt这两个文件夹，拟合模型model.fit时，只要一调用callbacks就会自动创建文件与文件夹拉！其中period=5是指每5个epoch记录一次模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='./logs'\n",
    "ckpt_path='./ckpt/titanic_{epoch:02d}_{val_loss:.2f}.ckpt'\n",
    "\n",
    "callbacks=[tf.keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "                                          histogram_freq=2),\n",
    "         tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path,\n",
    "                                           save_weights_only=True,\n",
    "                                           verbose=1,\n",
    "                                           period=5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 569 samples, validate on 143 samples\n",
      "WARNING:tensorflow:From /anaconda3/envs/dayuse/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.6587 - acc: 0.5729 - val_loss: 0.5481 - val_acc: 0.7133\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5834 - acc: 0.7170 - val_loss: 0.5115 - val_acc: 0.7902\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.5259 - acc: 0.7733 - val_loss: 0.4734 - val_acc: 0.7902\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.4949 - acc: 0.7926 - val_loss: 0.4680 - val_acc: 0.7902\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: saving model to ./ckpt/titanic_05_0.45.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From /anaconda3/envs/dayuse/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      " - 0s - loss: 0.4765 - acc: 0.7838 - val_loss: 0.4475 - val_acc: 0.7902\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4807 - acc: 0.7891 - val_loss: 0.4608 - val_acc: 0.7902\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4616 - acc: 0.7944 - val_loss: 0.4405 - val_acc: 0.7972\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4658 - acc: 0.7891 - val_loss: 0.4490 - val_acc: 0.7902\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4516 - acc: 0.8049 - val_loss: 0.4306 - val_acc: 0.8112\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: saving model to ./ckpt/titanic_10_0.43.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4471 - acc: 0.8014 - val_loss: 0.4312 - val_acc: 0.8112\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4576 - acc: 0.8014 - val_loss: 0.4303 - val_acc: 0.8182\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4372 - acc: 0.8155 - val_loss: 0.4292 - val_acc: 0.8112\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4500 - acc: 0.8014 - val_loss: 0.4298 - val_acc: 0.8182\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4428 - acc: 0.8225 - val_loss: 0.4319 - val_acc: 0.8182\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: saving model to ./ckpt/titanic_15_0.42.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4403 - acc: 0.8014 - val_loss: 0.4229 - val_acc: 0.8182\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4431 - acc: 0.8190 - val_loss: 0.4294 - val_acc: 0.8182\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4364 - acc: 0.8014 - val_loss: 0.4281 - val_acc: 0.8182\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4256 - acc: 0.8102 - val_loss: 0.4243 - val_acc: 0.8182\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4392 - acc: 0.7961 - val_loss: 0.4318 - val_acc: 0.8392\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 00020: saving model to ./ckpt/titanic_20_0.42.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4347 - acc: 0.7979 - val_loss: 0.4212 - val_acc: 0.8462\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4174 - acc: 0.8084 - val_loss: 0.4218 - val_acc: 0.8252\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4165 - acc: 0.8190 - val_loss: 0.4431 - val_acc: 0.7972\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4482 - acc: 0.8102 - val_loss: 0.4170 - val_acc: 0.8392\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4291 - acc: 0.8260 - val_loss: 0.4182 - val_acc: 0.8392\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 00025: saving model to ./ckpt/titanic_25_0.42.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4293 - acc: 0.8190 - val_loss: 0.4223 - val_acc: 0.8322\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4214 - acc: 0.8207 - val_loss: 0.4219 - val_acc: 0.8252\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4369 - acc: 0.8120 - val_loss: 0.4442 - val_acc: 0.8042\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4333 - acc: 0.8120 - val_loss: 0.4227 - val_acc: 0.8392\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4137 - acc: 0.8225 - val_loss: 0.4247 - val_acc: 0.8252\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 00030: saving model to ./ckpt/titanic_30_0.42.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4394 - acc: 0.8014 - val_loss: 0.4186 - val_acc: 0.8462\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4213 - acc: 0.8067 - val_loss: 0.4237 - val_acc: 0.8392\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4075 - acc: 0.8295 - val_loss: 0.4208 - val_acc: 0.8252\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4076 - acc: 0.8120 - val_loss: 0.4184 - val_acc: 0.8322\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4114 - acc: 0.8313 - val_loss: 0.4221 - val_acc: 0.8392\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 00035: saving model to ./ckpt/titanic_35_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4073 - acc: 0.8190 - val_loss: 0.4123 - val_acc: 0.8322\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4228 - acc: 0.8014 - val_loss: 0.4225 - val_acc: 0.8112\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4006 - acc: 0.8120 - val_loss: 0.4122 - val_acc: 0.8392\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8225 - val_loss: 0.4110 - val_acc: 0.8322\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4122 - acc: 0.8243 - val_loss: 0.4338 - val_acc: 0.8112\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 00040: saving model to ./ckpt/titanic_40_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4199 - acc: 0.8155 - val_loss: 0.4118 - val_acc: 0.8252\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4081 - acc: 0.8278 - val_loss: 0.4273 - val_acc: 0.8042\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4060 - acc: 0.8190 - val_loss: 0.4096 - val_acc: 0.8392\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4101 - acc: 0.8225 - val_loss: 0.4158 - val_acc: 0.8182\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4124 - acc: 0.8260 - val_loss: 0.4274 - val_acc: 0.8112\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 00045: saving model to ./ckpt/titanic_45_0.42.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.4117 - acc: 0.8207 - val_loss: 0.4168 - val_acc: 0.8252\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4014 - acc: 0.8348 - val_loss: 0.4226 - val_acc: 0.8252\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4048 - acc: 0.8278 - val_loss: 0.4139 - val_acc: 0.8112\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4133 - acc: 0.8207 - val_loss: 0.4152 - val_acc: 0.8252\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4058 - acc: 0.8313 - val_loss: 0.4114 - val_acc: 0.8322\n",
      "Epoch 50/100\n",
      "\n",
      "Epoch 00050: saving model to ./ckpt/titanic_50_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4125 - acc: 0.8207 - val_loss: 0.4150 - val_acc: 0.8182\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4131 - acc: 0.8225 - val_loss: 0.4141 - val_acc: 0.8322\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4165 - acc: 0.8207 - val_loss: 0.4120 - val_acc: 0.8322\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4098 - acc: 0.8295 - val_loss: 0.4191 - val_acc: 0.8182\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4118 - acc: 0.8313 - val_loss: 0.4141 - val_acc: 0.8182\n",
      "Epoch 55/100\n",
      "\n",
      "Epoch 00055: saving model to ./ckpt/titanic_55_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4111 - acc: 0.8172 - val_loss: 0.4118 - val_acc: 0.8252\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3962 - acc: 0.8260 - val_loss: 0.4003 - val_acc: 0.8182\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.3994 - acc: 0.8260 - val_loss: 0.4144 - val_acc: 0.8252\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.3910 - acc: 0.8295 - val_loss: 0.4033 - val_acc: 0.8182\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4101 - acc: 0.8137 - val_loss: 0.4055 - val_acc: 0.8182\n",
      "Epoch 60/100\n",
      "\n",
      "Epoch 00060: saving model to ./ckpt/titanic_60_0.40.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.3989 - acc: 0.8207 - val_loss: 0.4010 - val_acc: 0.8392\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3880 - acc: 0.8348 - val_loss: 0.4090 - val_acc: 0.8252\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.3828 - acc: 0.8348 - val_loss: 0.4070 - val_acc: 0.8182\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4029 - acc: 0.8348 - val_loss: 0.4155 - val_acc: 0.8322\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4135 - acc: 0.8243 - val_loss: 0.4017 - val_acc: 0.8322\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: saving model to ./ckpt/titanic_65_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4186 - acc: 0.8260 - val_loss: 0.4050 - val_acc: 0.8322\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4207 - acc: 0.8225 - val_loss: 0.4259 - val_acc: 0.8322\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4063 - acc: 0.8243 - val_loss: 0.3996 - val_acc: 0.8322\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3774 - acc: 0.8541 - val_loss: 0.4086 - val_acc: 0.8322\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4056 - acc: 0.8278 - val_loss: 0.4069 - val_acc: 0.8392\n",
      "Epoch 70/100\n",
      "\n",
      "Epoch 00070: saving model to ./ckpt/titanic_70_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.3977 - acc: 0.8330 - val_loss: 0.4065 - val_acc: 0.8671\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4004 - acc: 0.8366 - val_loss: 0.4171 - val_acc: 0.8182\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.3887 - acc: 0.8260 - val_loss: 0.4029 - val_acc: 0.8392\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3950 - acc: 0.8207 - val_loss: 0.4083 - val_acc: 0.8322\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3925 - acc: 0.8295 - val_loss: 0.4014 - val_acc: 0.8462\n",
      "Epoch 75/100\n",
      "\n",
      "Epoch 00075: saving model to ./ckpt/titanic_75_0.40.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.3970 - acc: 0.8383 - val_loss: 0.4046 - val_acc: 0.8392\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3886 - acc: 0.8489 - val_loss: 0.4077 - val_acc: 0.8252\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.3928 - acc: 0.8366 - val_loss: 0.4075 - val_acc: 0.8322\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.3937 - acc: 0.8418 - val_loss: 0.4004 - val_acc: 0.8462\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.3926 - acc: 0.8313 - val_loss: 0.4091 - val_acc: 0.8322\n",
      "Epoch 80/100\n",
      "\n",
      "Epoch 00080: saving model to ./ckpt/titanic_80_0.40.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.4039 - acc: 0.8313 - val_loss: 0.4019 - val_acc: 0.8462\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.3787 - acc: 0.8453 - val_loss: 0.4042 - val_acc: 0.8531\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.3899 - acc: 0.8489 - val_loss: 0.4043 - val_acc: 0.8462\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.3807 - acc: 0.8295 - val_loss: 0.4017 - val_acc: 0.8182\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.3917 - acc: 0.8243 - val_loss: 0.4148 - val_acc: 0.8112\n",
      "Epoch 85/100\n",
      "\n",
      "Epoch 00085: saving model to ./ckpt/titanic_85_0.42.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.3831 - acc: 0.8366 - val_loss: 0.4203 - val_acc: 0.7972\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4000 - acc: 0.8366 - val_loss: 0.4039 - val_acc: 0.8322\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3968 - acc: 0.8348 - val_loss: 0.4046 - val_acc: 0.8322\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3788 - acc: 0.8436 - val_loss: 0.3956 - val_acc: 0.8531\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3942 - acc: 0.8260 - val_loss: 0.3978 - val_acc: 0.8322\n",
      "Epoch 90/100\n",
      "\n",
      "Epoch 00090: saving model to ./ckpt/titanic_90_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.3810 - acc: 0.8436 - val_loss: 0.4116 - val_acc: 0.8392\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3931 - acc: 0.8278 - val_loss: 0.3976 - val_acc: 0.8531\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3840 - acc: 0.8278 - val_loss: 0.3970 - val_acc: 0.8531\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.3826 - acc: 0.8383 - val_loss: 0.3975 - val_acc: 0.8531\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.3956 - acc: 0.8313 - val_loss: 0.3928 - val_acc: 0.8531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "\n",
      "Epoch 00095: saving model to ./ckpt/titanic_95_0.41.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.3925 - acc: 0.8348 - val_loss: 0.4106 - val_acc: 0.8182\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.3949 - acc: 0.8348 - val_loss: 0.4060 - val_acc: 0.8462\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.3855 - acc: 0.8348 - val_loss: 0.3950 - val_acc: 0.8322\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.3907 - acc: 0.8172 - val_loss: 0.4040 - val_acc: 0.8322\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.3782 - acc: 0.8348 - val_loss: 0.3983 - val_acc: 0.8462\n",
      "Epoch 100/100\n",
      "\n",
      "Epoch 00100: saving model to ./ckpt/titanic_100_0.39.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x119c7e8d0>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      " - 0s - loss: 0.3831 - acc: 0.8489 - val_loss: 0.3915 - val_acc: 0.8531\n"
     ]
    }
   ],
   "source": [
    "train_history=model.fit(x=x_train,\n",
    "                        y=y_train,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=100,\n",
    "                        batch_size=40,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=2)\n",
    "\n",
    "#如果想要查看tensorboard，这个时候就可以去查看拉\n",
    "#进入终端\n",
    "#conda activate dayuse\n",
    "#tensorboard --logdir 文件夹路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6587369190578092,\n",
       "  0.5833902192450995,\n",
       "  0.5259014776071471,\n",
       "  0.4949246454846461,\n",
       "  0.47646250309969296,\n",
       "  0.48071800659431935,\n",
       "  0.4616326936938013,\n",
       "  0.4657607224683141,\n",
       "  0.4516465955124169,\n",
       "  0.4471079030439179,\n",
       "  0.4575946504390931,\n",
       "  0.43724586569781043,\n",
       "  0.44999320435817297,\n",
       "  0.4428041096521388,\n",
       "  0.4403024052903187,\n",
       "  0.4430569413466697,\n",
       "  0.4364031989304169,\n",
       "  0.42561847296247163,\n",
       "  0.43916666465819615,\n",
       "  0.43473590797824896,\n",
       "  0.4173639301465978,\n",
       "  0.4165492407676415,\n",
       "  0.448184239791022,\n",
       "  0.4291022886081823,\n",
       "  0.4293100233656241,\n",
       "  0.4213972911893379,\n",
       "  0.43686148576661027,\n",
       "  0.4332975215673028,\n",
       "  0.4137095805578366,\n",
       "  0.4394123462570573,\n",
       "  0.42134953074170334,\n",
       "  0.40750026747401025,\n",
       "  0.40762763267451724,\n",
       "  0.4113681821286783,\n",
       "  0.4072934159704587,\n",
       "  0.42278119502670947,\n",
       "  0.4005571176381438,\n",
       "  0.4062846559108037,\n",
       "  0.4122344888157501,\n",
       "  0.4198842688687866,\n",
       "  0.4081448931476144,\n",
       "  0.4059766840536691,\n",
       "  0.4101275075718053,\n",
       "  0.4123667151731012,\n",
       "  0.41170869092006884,\n",
       "  0.4014342088900467,\n",
       "  0.4048057206380975,\n",
       "  0.413336138105141,\n",
       "  0.4058105977536924,\n",
       "  0.412474252427609,\n",
       "  0.4131094426283308,\n",
       "  0.41654906273935716,\n",
       "  0.4098090584961098,\n",
       "  0.4118066090691069,\n",
       "  0.41113977587285905,\n",
       "  0.3962366884224025,\n",
       "  0.3994149363522789,\n",
       "  0.3909508591167537,\n",
       "  0.41012246170865213,\n",
       "  0.398922745708003,\n",
       "  0.3880455612298265,\n",
       "  0.3827667573633848,\n",
       "  0.40292720844959334,\n",
       "  0.4134844443605319,\n",
       "  0.4186264635808439,\n",
       "  0.4207434919261765,\n",
       "  0.4063456604790813,\n",
       "  0.3773959688645884,\n",
       "  0.4056151114364919,\n",
       "  0.39766051762971394,\n",
       "  0.40044168470613983,\n",
       "  0.3887013134616959,\n",
       "  0.3949741301092406,\n",
       "  0.39251266527259704,\n",
       "  0.3969945078470166,\n",
       "  0.38856760136167695,\n",
       "  0.39280173187725154,\n",
       "  0.39372870226526513,\n",
       "  0.3926292865787533,\n",
       "  0.4038766609972935,\n",
       "  0.3787190701504793,\n",
       "  0.38990158848268075,\n",
       "  0.38073948942295066,\n",
       "  0.3916867786006894,\n",
       "  0.38312904088903604,\n",
       "  0.3999765347198359,\n",
       "  0.39681167133244144,\n",
       "  0.3787785716132246,\n",
       "  0.3941895718733749,\n",
       "  0.3810486694002403,\n",
       "  0.39305667864626864,\n",
       "  0.38398772925924124,\n",
       "  0.3825953768301094,\n",
       "  0.3956032129289396,\n",
       "  0.3925301219960298,\n",
       "  0.3948682782310593,\n",
       "  0.385512565581786,\n",
       "  0.3906521834629491,\n",
       "  0.37824401408695796,\n",
       "  0.3830535085789977],\n",
       " 'acc': [0.572935,\n",
       "  0.71704745,\n",
       "  0.77328646,\n",
       "  0.79261863,\n",
       "  0.7838313,\n",
       "  0.7891037,\n",
       "  0.7943761,\n",
       "  0.7891037,\n",
       "  0.8049209,\n",
       "  0.80140597,\n",
       "  0.80140597,\n",
       "  0.81546575,\n",
       "  0.80140597,\n",
       "  0.8224956,\n",
       "  0.80140597,\n",
       "  0.8189807,\n",
       "  0.80140597,\n",
       "  0.8101933,\n",
       "  0.7961336,\n",
       "  0.797891,\n",
       "  0.80843586,\n",
       "  0.8189807,\n",
       "  0.8101933,\n",
       "  0.8260105,\n",
       "  0.8189807,\n",
       "  0.82073814,\n",
       "  0.8119508,\n",
       "  0.8119508,\n",
       "  0.8224956,\n",
       "  0.80140597,\n",
       "  0.80667835,\n",
       "  0.8295255,\n",
       "  0.8119508,\n",
       "  0.831283,\n",
       "  0.8189807,\n",
       "  0.80140597,\n",
       "  0.8119508,\n",
       "  0.8224956,\n",
       "  0.8242531,\n",
       "  0.81546575,\n",
       "  0.827768,\n",
       "  0.8189807,\n",
       "  0.8224956,\n",
       "  0.8260105,\n",
       "  0.82073814,\n",
       "  0.8347979,\n",
       "  0.827768,\n",
       "  0.82073814,\n",
       "  0.831283,\n",
       "  0.82073814,\n",
       "  0.8224956,\n",
       "  0.82073814,\n",
       "  0.8295255,\n",
       "  0.831283,\n",
       "  0.8172232,\n",
       "  0.8260105,\n",
       "  0.8260105,\n",
       "  0.8295255,\n",
       "  0.81370825,\n",
       "  0.82073814,\n",
       "  0.8347979,\n",
       "  0.8347979,\n",
       "  0.8347979,\n",
       "  0.8242531,\n",
       "  0.8260105,\n",
       "  0.8224956,\n",
       "  0.8242531,\n",
       "  0.85413,\n",
       "  0.827768,\n",
       "  0.8330404,\n",
       "  0.83655536,\n",
       "  0.8260105,\n",
       "  0.82073814,\n",
       "  0.8295255,\n",
       "  0.8383128,\n",
       "  0.84885764,\n",
       "  0.83655536,\n",
       "  0.84182775,\n",
       "  0.831283,\n",
       "  0.831283,\n",
       "  0.8453427,\n",
       "  0.84885764,\n",
       "  0.8295255,\n",
       "  0.8242531,\n",
       "  0.83655536,\n",
       "  0.83655536,\n",
       "  0.8347979,\n",
       "  0.84358525,\n",
       "  0.8260105,\n",
       "  0.84358525,\n",
       "  0.827768,\n",
       "  0.827768,\n",
       "  0.8383128,\n",
       "  0.831283,\n",
       "  0.8347979,\n",
       "  0.8347979,\n",
       "  0.8347979,\n",
       "  0.8172232,\n",
       "  0.8347979,\n",
       "  0.84885764],\n",
       " 'val_loss': [0.5480962654093763,\n",
       "  0.511516192993084,\n",
       "  0.4734067493802184,\n",
       "  0.4680468237900234,\n",
       "  0.4475478404885405,\n",
       "  0.46078142065268296,\n",
       "  0.44046531503017133,\n",
       "  0.448980741567545,\n",
       "  0.4305663588163736,\n",
       "  0.4311909925687563,\n",
       "  0.4303071509291242,\n",
       "  0.429182971899326,\n",
       "  0.4298268354439235,\n",
       "  0.4319173160132828,\n",
       "  0.422890298641645,\n",
       "  0.4294030614249356,\n",
       "  0.4280793333387041,\n",
       "  0.42431741723647487,\n",
       "  0.4318374935146812,\n",
       "  0.42119471489132704,\n",
       "  0.42179620224279124,\n",
       "  0.44313600680211207,\n",
       "  0.41700291571083603,\n",
       "  0.41820625533590783,\n",
       "  0.42225934679691607,\n",
       "  0.4219029923002203,\n",
       "  0.44418860565532337,\n",
       "  0.42266775823973274,\n",
       "  0.42472025918793843,\n",
       "  0.4185861055250768,\n",
       "  0.4237058554495965,\n",
       "  0.4207805032496686,\n",
       "  0.41840678119992875,\n",
       "  0.4221166472334962,\n",
       "  0.4122647972373696,\n",
       "  0.42250415182613826,\n",
       "  0.4121741621227531,\n",
       "  0.41100893279055617,\n",
       "  0.43378901085653504,\n",
       "  0.4117673843890637,\n",
       "  0.4273400175404715,\n",
       "  0.40959863896136517,\n",
       "  0.4157666829707739,\n",
       "  0.42741899432002245,\n",
       "  0.41682212877940467,\n",
       "  0.42255766783560905,\n",
       "  0.41388556069427435,\n",
       "  0.4151803517675066,\n",
       "  0.4114456549807862,\n",
       "  0.41499369190289426,\n",
       "  0.4140620052397668,\n",
       "  0.41197855374613007,\n",
       "  0.4190714375956075,\n",
       "  0.4140868897621448,\n",
       "  0.41177246453878763,\n",
       "  0.4003258862278678,\n",
       "  0.41444398264784915,\n",
       "  0.4033291118961948,\n",
       "  0.40554426183233727,\n",
       "  0.40099496399606027,\n",
       "  0.40896427131199337,\n",
       "  0.40700391330919067,\n",
       "  0.4155446655683584,\n",
       "  0.4017389996068461,\n",
       "  0.40502720779472295,\n",
       "  0.4258717571521972,\n",
       "  0.39957469555881475,\n",
       "  0.4085646375909552,\n",
       "  0.406851869571459,\n",
       "  0.4064824235189211,\n",
       "  0.417114326795498,\n",
       "  0.40290510320996903,\n",
       "  0.4083397715658575,\n",
       "  0.4014255552441924,\n",
       "  0.40457689741274694,\n",
       "  0.40767767421015494,\n",
       "  0.4075055479794949,\n",
       "  0.4003595522233656,\n",
       "  0.40912625089391963,\n",
       "  0.40191270775728294,\n",
       "  0.4042360219922099,\n",
       "  0.4043031351549642,\n",
       "  0.4016677345429267,\n",
       "  0.4148352731774737,\n",
       "  0.4203430822679213,\n",
       "  0.4038731261983618,\n",
       "  0.4045523198751303,\n",
       "  0.3956489075313915,\n",
       "  0.3977631813996322,\n",
       "  0.4115715083125588,\n",
       "  0.39758275334651655,\n",
       "  0.3969635158985645,\n",
       "  0.3975165532185481,\n",
       "  0.3928485946221785,\n",
       "  0.41057749498974194,\n",
       "  0.4060247031958787,\n",
       "  0.39500831494798194,\n",
       "  0.4040187370110225,\n",
       "  0.39833670583638275,\n",
       "  0.39154159209944983],\n",
       " 'val_acc': [0.7132867,\n",
       "  0.7902098,\n",
       "  0.7902098,\n",
       "  0.7902098,\n",
       "  0.7902098,\n",
       "  0.7902098,\n",
       "  0.7972028,\n",
       "  0.7902098,\n",
       "  0.8111888,\n",
       "  0.8111888,\n",
       "  0.8181818,\n",
       "  0.8111888,\n",
       "  0.8181818,\n",
       "  0.8181818,\n",
       "  0.8181818,\n",
       "  0.8181818,\n",
       "  0.8181818,\n",
       "  0.8181818,\n",
       "  0.83916086,\n",
       "  0.84615386,\n",
       "  0.8251748,\n",
       "  0.7972028,\n",
       "  0.83916086,\n",
       "  0.83916086,\n",
       "  0.8321678,\n",
       "  0.8251748,\n",
       "  0.8041958,\n",
       "  0.83916086,\n",
       "  0.8251748,\n",
       "  0.84615386,\n",
       "  0.83916086,\n",
       "  0.8251748,\n",
       "  0.8321678,\n",
       "  0.83916086,\n",
       "  0.8321678,\n",
       "  0.8111888,\n",
       "  0.83916086,\n",
       "  0.8321678,\n",
       "  0.8111888,\n",
       "  0.8251748,\n",
       "  0.8041958,\n",
       "  0.83916086,\n",
       "  0.8181818,\n",
       "  0.8111888,\n",
       "  0.8251748,\n",
       "  0.8251748,\n",
       "  0.8111888,\n",
       "  0.8251748,\n",
       "  0.8321678,\n",
       "  0.8181818,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.8181818,\n",
       "  0.8181818,\n",
       "  0.8251748,\n",
       "  0.8181818,\n",
       "  0.8251748,\n",
       "  0.8181818,\n",
       "  0.8181818,\n",
       "  0.83916086,\n",
       "  0.8251748,\n",
       "  0.8181818,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.83916086,\n",
       "  0.86713284,\n",
       "  0.8181818,\n",
       "  0.83916086,\n",
       "  0.8321678,\n",
       "  0.84615386,\n",
       "  0.83916086,\n",
       "  0.8251748,\n",
       "  0.8321678,\n",
       "  0.84615386,\n",
       "  0.8321678,\n",
       "  0.84615386,\n",
       "  0.85314685,\n",
       "  0.84615386,\n",
       "  0.8181818,\n",
       "  0.8111888,\n",
       "  0.7972028,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.85314685,\n",
       "  0.8321678,\n",
       "  0.83916086,\n",
       "  0.85314685,\n",
       "  0.85314685,\n",
       "  0.85314685,\n",
       "  0.85314685,\n",
       "  0.8181818,\n",
       "  0.84615386,\n",
       "  0.8321678,\n",
       "  0.8321678,\n",
       "  0.84615386,\n",
       "  0.85314685]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从checkpoint文件中恢复模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest=tf.train.latest_checkpoint('./ckpt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x1a37539080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 恢复模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 57us/sample - loss: 0.4992 - acc: 0.7989\n",
      "acc:79.89%\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model.evaluate(x_test,y_test)\n",
    "print ('acc:{:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
